{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 03 - Due Friday, November 18 at 4pm\n",
    "\n",
    "*Objectives*: Use Spark to process and perform basic analysis on non-relational data, including its DataFrame and SQL interfaces.\n",
    "\n",
    "*Grading criteria*: The tasks should all be completed, and questions should all be answered with Python code, SQL queries, shell commands, and markdown cells.  The notebook itself should be completely reproducible (using AWS EC2 instance based on the provided AMI) from start to finish; another person should be able to use the code to obtain the same results as yours.  Note that you will receive no more than partial credit if you do not add text/markdown cells explaining your thinking when appropriate.\n",
    "\n",
    "\n",
    "*Deadline*: Friday, November 18, 4 pm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Setup\n",
    "\n",
    "Begin by setting up Spark and fetching the project data.  \n",
    "\n",
    "**Note**: you may want to use a larger EC2 instance type than normal.  This project was prepared using a `t2.xlarge` instance.  Just remember that the larger the instance, the higher the per-hour charge, so be sure to remember to shut your instance down when you're done, as always.\n",
    "\n",
    "### About the data\n",
    "\n",
    "We will use JSON data from Twitter; we saw an example of this in class.  It should parse cleanly, allowing you to focus on analysis.\n",
    "\n",
    "This data was gathered using GWU Libraries' [Social Feed Manager](http://sfm.library.gwu.edu/) application during a recent game of the MLB World Series featuring the Los Angeles Dodgers and Houston Astros.  This first file tells you a little bit about how it was gathered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First make sure you are working from the right working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This below file provides context and detail information on the files we are going to work with\n",
    "#### in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-18 06:33:01--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611-README.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.204.64, 54.231.201.16, 54.231.234.112, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.204.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1920 (1.9K) [text/plain]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611-README.txt.1’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>]   1.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-11-18 06:33:01 (20.3 MB/s) - ‘9670f3399f774789b7c3e18975d25611-README.txt.1’ saved [1920/1920]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611-README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an export created with Social Feed Manager.\n",
      "\n",
      "EXPORT INFORMATION\n",
      "Selected seeds: All seeds\n",
      "Export id: 9670f3399f774789b7c3e18975d25611\n",
      "Export type: twitter_filter\n",
      "Format: Full JSON\n",
      "Export completed:  Oct. 30, 2017, 11:21:04 p.m. EDT\n",
      "Deduplicate: No\n",
      "\n",
      "COLLECTION INFORMATION\n",
      "Collection name: test set for world series\n",
      "Collection id: 34e3f7460b5c4df09d64a1e61fd81238\n",
      "Collection set: mlb-test (collection set id d6e8c27b1bc942e78790aa55a82b3a7a)\n",
      "Harvest type: Twitter filter\n",
      "Collection description: running for just one hour, just for fun.\n",
      "\n",
      "Harvest options:\n",
      "Media: No\n",
      "Web resources: No\n",
      "\n",
      "Seeds:\n",
      "* Track: dodgers,astros - Active\n",
      "\n",
      "Change log:\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 30, 2017, 10:59:56 p.m. EDT by dchud:\n",
      "* is_active: \"True\" changed to \"False\"\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 30, 2017, 10:58:51 p.m. EDT by dchud:\n",
      "* is_on: \"True\" changed to \"False\"\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 29, 2017, 8:01:24 p.m. EDT by dchud:\n",
      "* is_on: \"False\" changed to \"True\"\n",
      "\n",
      "Change to Track: dodgers,astros (seed) on Oct. 29, 2017, 8:01:21 p.m. EDT by dchud:\n",
      "* token: \"blank\" changed to \"{\"track\": \"dodgers,astros\"}\"\n",
      "* is_active: \"blank\" changed to \"True\"\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 29, 2017, 8:01:06 p.m. EDT by dchud:\n",
      "* credential: \"blank\" changed to \"dchud's twitter credential\"\n",
      "* harvest_type: \"blank\" changed to \"twitter_filter\"\n",
      "* is_on: \"blank\" changed to \"False\"\n",
      "* end_date: \"blank\" changed to \"Oct. 31, 2017, 8:00:38 p.m. EDT\"\n",
      "* description: \"blank\" changed to \"running for just one hour, just for fun.\"\n",
      "* collection_set: \"blank\" changed to \"mlb-test\"\n",
      "* is_active: \"blank\" changed to \"True\"\n",
      "* visibility: \"blank\" changed to \"default\"\n",
      "* harvest_options: \"blank\" changed to \"{\"media\": false, \"web_resources\": false}\"\n",
      "* name: \"blank\" changed to \"test set for world series\"\n",
      "\n",
      "\n",
      "Created on Oct. 30, 2017, 11:21:04 p.m. EDT\n"
     ]
    }
   ],
   "source": [
    "!cat 9670f3399f774789b7c3e18975d25611-README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important pieces in that metadata are:\n",
    "\n",
    " * It tracked tweets that mentioned \"dodgers\" or \"astros\".  Every item in this set should refer to one or the other, or both.\n",
    " * This data was not deduplicated; we may see individual items more than once.\n",
    " * Data was collected between October 29 and October 30.  Game 5 of the Series was played during this time.\n",
    " \n",
    "You should not need to know anything about baseball to complete this assignment.\n",
    "\n",
    "**Please note**: sometimes social media data contains offensive material.  This data set has not been filtered; if you do come across something inappropriate, please do your best to ignore it if you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data\n",
    "\n",
    "The following files are available:\n",
    "\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_004.json\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_005.json\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json\n",
    " \n",
    "### Q1.1 - Upload the above files to your instance using `wget`.  Verify the file sizes using the command line. \n",
    "\n",
    "Each file should contain exactly 100,000 tweets.  \n",
    "\n",
    "*Note*: you are required to use all files.  It will be easier to process more data if you use a larger EC2 instance type, as suggested above.  Use the exact same set of files throughout the assignment.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the files using wget. Add more if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-18 06:33:12--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.107.238, 52.216.112.150, 52.216.144.61, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.107.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 595711407 (568M) [application/json]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611_003.json’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>] 568.11M  77.5MB/s    in 6.9s    \n",
      "\n",
      "2022-11-18 06:33:19 (82.1 MB/s) - ‘9670f3399f774789b7c3e18975d25611_003.json’ saved [595711407/595711407]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-18 06:33:24--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_004.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.112.150, 52.216.129.173, 52.216.244.254, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.112.150|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 549995846 (525M) [application/json]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611_004.json’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>] 524.52M  84.2MB/s    in 6.6s    \n",
      "\n",
      "2022-11-18 06:33:31 (79.2 MB/s) - ‘9670f3399f774789b7c3e18975d25611_004.json’ saved [549995846/549995846]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_004.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-18 06:33:33--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_005.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.216.240, 52.217.78.62, 52.217.85.142, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.216.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 530698683 (506M) [application/json]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611_005.json’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>] 506.11M  83.8MB/s    in 6.3s    \n",
      "\n",
      "2022-11-18 06:33:40 (80.8 MB/s) - ‘9670f3399f774789b7c3e18975d25611_005.json’ saved [530698683/530698683]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_005.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-18 06:33:42--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.53.160, 52.216.139.85, 52.216.184.213, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.53.160|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 545081593 (520M) [application/json]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611_006.json’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>] 519.83M  91.5MB/s    in 5.8s    \n",
      "\n",
      "2022-11-18 06:33:48 (90.1 MB/s) - ‘9670f3399f774789b7c3e18975d25611_006.json’ saved [545081593/545081593]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the files have exactly 100,000 tweets using the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100000 9670f3399f774789b7c3e18975d25611_003.json\n",
      "    100000 9670f3399f774789b7c3e18975d25611_004.json\n",
      "    100000 9670f3399f774789b7c3e18975d25611_005.json\n",
      "    100000 9670f3399f774789b7c3e18975d25611_006.json\n",
      "    400000 total\n"
     ]
    }
   ],
   "source": [
    "# Write you code here. \n",
    "!wc -l *.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, here is the text of one Tweet, randomly selected from one of these files.  You might wish to study its structure and refer to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat *.json | shuf -n 1 > example-tweet.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quote_count\": 0,\n",
      "  \"contributors\": null,\n",
      "  \"truncated\": false,\n",
      "  \"text\": \"\\ud83d\\udc40\\ud83d\\udc40\\ud83d\\udc40 https://t.co/wbd9uiFLnc\",\n",
      "  \"is_quote_status\": true,\n",
      "  \"in_reply_to_status_id\": null,\n",
      "  \"reply_count\": 0,\n",
      "  \"id\": 924878222365425664,\n",
      "  \"favorite_count\": 0,\n",
      "  \"entities\": {\n",
      "    \"user_mentions\": [],\n",
      "    \"symbols\": [],\n",
      "    \"hashtags\": [],\n",
      "    \"urls\": [\n",
      "      {\n",
      "        \"url\": \"https://t.co/wbd9uiFLnc\",\n",
      "        \"indices\": [\n",
      "          4,\n",
      "          27\n",
      "        ],\n",
      "        \"expanded_url\": \"https://twitter.com/NikoNikosGreek/status/924840978598518785\",\n",
      "        \"display_url\": \"twitter.com/NikoNikosGreek\\u2026\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"quoted_status_id\": 924840978598518785,\n",
      "  \"retweeted\": false,\n",
      "  \"coordinates\": null,\n",
      "  \"timestamp_ms\": \"1509343126275\",\n",
      "  \"quoted_status\": {\n",
      "    \"quote_count\": 13,\n",
      "    \"contributors\": null,\n",
      "    \"truncated\": true,\n",
      "    \"text\": \"If the Astros win and pull this off tonight I will sell my original lamb and beef gyros sandwiches tomorow at 50% o\\u2026 https://t.co/UvB5mlPqFQ\",\n",
      "    \"is_quote_status\": false,\n",
      "    \"in_reply_to_status_id\": null,\n",
      "    \"reply_count\": 5,\n",
      "    \"id\": 924840978598518785,\n",
      "    \"favorite_count\": 116,\n",
      "    \"entities\": {\n",
      "      \"user_mentions\": [],\n",
      "      \"symbols\": [],\n",
      "      \"hashtags\": [],\n",
      "      \"urls\": [\n",
      "        {\n",
      "          \"url\": \"https://t.co/UvB5mlPqFQ\",\n",
      "          \"indices\": [\n",
      "            117,\n",
      "            140\n",
      "          ],\n",
      "          \"expanded_url\": \"https://twitter.com/i/web/status/924840978598518785\",\n",
      "          \"display_url\": \"twitter.com/i/web/status/9\\u2026\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"retweeted\": false,\n",
      "    \"coordinates\": null,\n",
      "    \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\",\n",
      "    \"in_reply_to_screen_name\": null,\n",
      "    \"id_str\": \"924840978598518785\",\n",
      "    \"display_text_range\": [\n",
      "      0,\n",
      "      140\n",
      "    ],\n",
      "    \"retweet_count\": 58,\n",
      "    \"in_reply_to_user_id\": null,\n",
      "    \"favorited\": false,\n",
      "    \"user\": {\n",
      "      \"follow_request_sent\": null,\n",
      "      \"profile_use_background_image\": true,\n",
      "      \"default_profile_image\": false,\n",
      "      \"id\": 40167782,\n",
      "      \"default_profile\": false,\n",
      "      \"verified\": false,\n",
      "      \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/532286099201069056/61bdV8UE_normal.jpeg\",\n",
      "      \"profile_sidebar_fill_color\": \"40BAF7\",\n",
      "      \"profile_text_color\": \"030303\",\n",
      "      \"followers_count\": 3242,\n",
      "      \"profile_sidebar_border_color\": \"000000\",\n",
      "      \"id_str\": \"40167782\",\n",
      "      \"profile_background_color\": \"EEF07D\",\n",
      "      \"listed_count\": 184,\n",
      "      \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/74483634/Niko-Nikos.800w_600h.jpg\",\n",
      "      \"utc_offset\": -18000,\n",
      "      \"statuses_count\": 2026,\n",
      "      \"description\": \"Since 1977 we've proudly served the Montrose community great Greek food with a great atmosphere. Now serving 4 Houston area locations.\",\n",
      "      \"friends_count\": 132,\n",
      "      \"location\": \"Houston, TX\",\n",
      "      \"profile_link_color\": \"091799\",\n",
      "      \"profile_image_url\": \"http://pbs.twimg.com/profile_images/532286099201069056/61bdV8UE_normal.jpeg\",\n",
      "      \"following\": null,\n",
      "      \"geo_enabled\": true,\n",
      "      \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/40167782/1401481439\",\n",
      "      \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/74483634/Niko-Nikos.800w_600h.jpg\",\n",
      "      \"name\": \"Niko Niko's\",\n",
      "      \"lang\": \"en\",\n",
      "      \"profile_background_tile\": true,\n",
      "      \"favourites_count\": 448,\n",
      "      \"screen_name\": \"NikoNikosGreek\",\n",
      "      \"notifications\": null,\n",
      "      \"url\": \"http://www.nikonikos.com/\",\n",
      "      \"created_at\": \"Fri May 15 03:39:58 +0000 2009\",\n",
      "      \"contributors_enabled\": false,\n",
      "      \"time_zone\": \"Central Time (US & Canada)\",\n",
      "      \"protected\": false,\n",
      "      \"translator_type\": \"none\",\n",
      "      \"is_translator\": false\n",
      "    },\n",
      "    \"geo\": null,\n",
      "    \"in_reply_to_user_id_str\": null,\n",
      "    \"possibly_sensitive\": false,\n",
      "    \"lang\": \"en\",\n",
      "    \"extended_tweet\": {\n",
      "      \"display_text_range\": [\n",
      "        0,\n",
      "        140\n",
      "      ],\n",
      "      \"entities\": {\n",
      "        \"user_mentions\": [],\n",
      "        \"symbols\": [],\n",
      "        \"hashtags\": [],\n",
      "        \"urls\": [],\n",
      "        \"media\": [\n",
      "          {\n",
      "            \"expanded_url\": \"https://twitter.com/NikoNikosGreek/status/924840978598518785/photo/1\",\n",
      "            \"display_url\": \"pic.twitter.com/vYpEY1Lb6n\",\n",
      "            \"url\": \"https://t.co/vYpEY1Lb6n\",\n",
      "            \"media_url_https\": \"https://pbs.twimg.com/media/DNWx9n4UMAAfPoB.jpg\",\n",
      "            \"id_str\": \"924840970729828352\",\n",
      "            \"sizes\": {\n",
      "              \"large\": {\n",
      "                \"h\": 1077,\n",
      "                \"resize\": \"fit\",\n",
      "                \"w\": 1077\n",
      "              },\n",
      "              \"small\": {\n",
      "                \"h\": 680,\n",
      "                \"resize\": \"fit\",\n",
      "                \"w\": 680\n",
      "              },\n",
      "              \"medium\": {\n",
      "                \"h\": 1077,\n",
      "                \"resize\": \"fit\",\n",
      "                \"w\": 1077\n",
      "              },\n",
      "              \"thumb\": {\n",
      "                \"h\": 150,\n",
      "                \"resize\": \"crop\",\n",
      "                \"w\": 150\n",
      "              }\n",
      "            },\n",
      "            \"indices\": [\n",
      "              141,\n",
      "              164\n",
      "            ],\n",
      "            \"type\": \"photo\",\n",
      "            \"id\": 924840970729828352,\n",
      "            \"media_url\": \"http://pbs.twimg.com/media/DNWx9n4UMAAfPoB.jpg\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"extended_entities\": {\n",
      "        \"media\": [\n",
      "          {\n",
      "            \"expanded_url\": \"https://twitter.com/NikoNikosGreek/status/924840978598518785/photo/1\",\n",
      "            \"display_url\": \"pic.twitter.com/vYpEY1Lb6n\",\n",
      "            \"url\": \"https://t.co/vYpEY1Lb6n\",\n",
      "            \"media_url_https\": \"https://pbs.twimg.com/media/DNWx9n4UMAAfPoB.jpg\",\n",
      "            \"id_str\": \"924840970729828352\",\n",
      "            \"sizes\": {\n",
      "              \"large\": {\n",
      "                \"h\": 1077,\n",
      "                \"resize\": \"fit\",\n",
      "                \"w\": 1077\n",
      "              },\n",
      "              \"small\": {\n",
      "                \"h\": 680,\n",
      "                \"resize\": \"fit\",\n",
      "                \"w\": 680\n",
      "              },\n",
      "              \"medium\": {\n",
      "                \"h\": 1077,\n",
      "                \"resize\": \"fit\",\n",
      "                \"w\": 1077\n",
      "              },\n",
      "              \"thumb\": {\n",
      "                \"h\": 150,\n",
      "                \"resize\": \"crop\",\n",
      "                \"w\": 150\n",
      "              }\n",
      "            },\n",
      "            \"indices\": [\n",
      "              141,\n",
      "              164\n",
      "            ],\n",
      "            \"type\": \"photo\",\n",
      "            \"id\": 924840970729828352,\n",
      "            \"media_url\": \"http://pbs.twimg.com/media/DNWx9n4UMAAfPoB.jpg\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"full_text\": \"If the Astros win and pull this off tonight I will sell my original lamb and beef gyros sandwiches tomorow at 50% off at all 3 Niko NIkos!!! https://t.co/vYpEY1Lb6n\"\n",
      "    },\n",
      "    \"created_at\": \"Mon Oct 30 03:30:46 +0000 2017\",\n",
      "    \"filter_level\": \"low\",\n",
      "    \"in_reply_to_status_id_str\": null,\n",
      "    \"place\": {\n",
      "      \"full_name\": \"Houston, TX\",\n",
      "      \"url\": \"https://api.twitter.com/1.1/geo/id/1c69a67ad480e1b1.json\",\n",
      "      \"country\": \"United States\",\n",
      "      \"place_type\": \"city\",\n",
      "      \"bounding_box\": {\n",
      "        \"type\": \"Polygon\",\n",
      "        \"coordinates\": [\n",
      "          [\n",
      "            [\n",
      "              -95.823268,\n",
      "              29.522325\n",
      "            ],\n",
      "            [\n",
      "              -95.823268,\n",
      "              30.154665\n",
      "            ],\n",
      "            [\n",
      "              -95.069705,\n",
      "              30.154665\n",
      "            ],\n",
      "            [\n",
      "              -95.069705,\n",
      "              29.522325\n",
      "            ]\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"country_code\": \"US\",\n",
      "      \"attributes\": {},\n",
      "      \"id\": \"1c69a67ad480e1b1\",\n",
      "      \"name\": \"Houston\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\",\n",
      "  \"in_reply_to_screen_name\": null,\n",
      "  \"id_str\": \"924878222365425664\",\n",
      "  \"display_text_range\": [\n",
      "    0,\n",
      "    3\n",
      "  ],\n",
      "  \"retweet_count\": 0,\n",
      "  \"in_reply_to_user_id\": null,\n",
      "  \"favorited\": false,\n",
      "  \"user\": {\n",
      "    \"follow_request_sent\": null,\n",
      "    \"profile_use_background_image\": true,\n",
      "    \"default_profile_image\": false,\n",
      "    \"id\": 351325426,\n",
      "    \"default_profile\": false,\n",
      "    \"verified\": false,\n",
      "    \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/790611889621348352/tltpiJTg_normal.jpg\",\n",
      "    \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "    \"profile_text_color\": \"333333\",\n",
      "    \"followers_count\": 7570,\n",
      "    \"profile_sidebar_border_color\": \"FFFFFF\",\n",
      "    \"id_str\": \"351325426\",\n",
      "    \"profile_background_color\": \"C0DEED\",\n",
      "    \"listed_count\": 23,\n",
      "    \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/805397264/9ae00a57d576b6f74d98b8ec9a903cba.jpeg\",\n",
      "    \"utc_offset\": -18000,\n",
      "    \"statuses_count\": 19908,\n",
      "    \"description\": \"----   Buy the ticket  ------  Take the ride  ----  I write about travel & cars. I love soccer & bourbon. I will travel wherever the cheap airfare blows me.\",\n",
      "    \"friends_count\": 1301,\n",
      "    \"location\": \"H-Town\",\n",
      "    \"profile_link_color\": \"1B95E0\",\n",
      "    \"profile_image_url\": \"http://pbs.twimg.com/profile_images/790611889621348352/tltpiJTg_normal.jpg\",\n",
      "    \"following\": null,\n",
      "    \"geo_enabled\": true,\n",
      "    \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/351325426/1477331265\",\n",
      "    \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/805397264/9ae00a57d576b6f74d98b8ec9a903cba.jpeg\",\n",
      "    \"name\": \"Wilson\",\n",
      "    \"lang\": \"en\",\n",
      "    \"profile_background_tile\": true,\n",
      "    \"favourites_count\": 24108,\n",
      "    \"screen_name\": \"WilsonCalvert\",\n",
      "    \"notifications\": null,\n",
      "    \"url\": null,\n",
      "    \"created_at\": \"Tue Aug 09 02:55:22 +0000 2011\",\n",
      "    \"contributors_enabled\": false,\n",
      "    \"time_zone\": \"Central Time (US & Canada)\",\n",
      "    \"protected\": false,\n",
      "    \"translator_type\": \"none\",\n",
      "    \"is_translator\": false\n",
      "  },\n",
      "  \"geo\": null,\n",
      "  \"in_reply_to_user_id_str\": null,\n",
      "  \"possibly_sensitive\": false,\n",
      "  \"lang\": \"und\",\n",
      "  \"created_at\": \"Mon Oct 30 05:58:46 +0000 2017\",\n",
      "  \"quoted_status_id_str\": \"924840978598518785\",\n",
      "  \"filter_level\": \"low\",\n",
      "  \"in_reply_to_status_id_str\": null,\n",
      "  \"place\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(json.load(open(\"example-tweet.json\")), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find several key elements in this example; the text, time, and language of the tweet, whether it was a reply to another user, the user's screen name along with their primary language and other account information like creation date, follower/friend/tweet counts, and perhaps their location.  \n",
    "If there are hashtags, user mentions, or urls present in their tweet, they will be present in the `entities` section; these are not present in every tweet.  If this is a retweet, you will see the original tweet and its information nested within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 - Start up Spark, and verify the file sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our normal startup sequence here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SPARK_HOME'] = '/usr/local/lib/spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 09:01:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkContext(appName='project-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-25-82.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>project-03</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=project-03>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlc = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f25dd2365b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 09:01:41 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "tweets = sqlc.read.json(\"*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that Spark has loaded the same number of tweets you saw before:\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see exactly the same number of tweets in Spark that you saw on the command line? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets1 = sqlc.read.json(\"9670f3399f774789b7c3e18975d25611_003.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets2 = sqlc.read.json(\"9670f3399f774789b7c3e18975d25611_004.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets3 = sqlc.read.json(\"9670f3399f774789b7c3e18975d25611_005.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets4 = sqlc.read.json(\"9670f3399f774789b7c3e18975d25611_006.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets4.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Comparing DataFrames and Spark SQL\n",
    "\n",
    "For the next three questions, we will look at operations using both DataFrames and SQL queries. Note that `tweets` is already a DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To issue SQL queries, we need to register a table based on `tweets`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all well and good, but how well did schema inference work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.createOrReplaceTempView(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 - Which 10 languages are most commonly used in tweets?  Verify your result by executing it with both the dataframe and with SQL.\n",
    "\n",
    "Hint: for the dataframe, use `groupBy`, `count`, and `orderBy`.  See the documentation at https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html for details on these and other functions.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contributors',\n",
       " 'coordinates',\n",
       " 'created_at',\n",
       " 'display_text_range',\n",
       " 'entities',\n",
       " 'extended_entities',\n",
       " 'extended_tweet',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'filter_level',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'is_quote_status',\n",
       " 'lang',\n",
       " 'place',\n",
       " 'possibly_sensitive',\n",
       " 'quote_count',\n",
       " 'quoted_status',\n",
       " 'quoted_status_id',\n",
       " 'quoted_status_id_str',\n",
       " 'reply_count',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'retweeted_status',\n",
       " 'source',\n",
       " 'text',\n",
       " 'timestamp_ms',\n",
       " 'truncated',\n",
       " 'user']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|lang| count|\n",
      "+----+------+\n",
      "|  en|346302|\n",
      "|  es| 31869|\n",
      "| und| 14660|\n",
      "|  in|  2355|\n",
      "|  fr|   997|\n",
      "|  pt|   914|\n",
      "|  tl|   485|\n",
      "|  ht|   377|\n",
      "|  nl|   347|\n",
      "|  it|   285|\n",
      "+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets.groupby('lang').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|lang|count(1)|\n",
      "+----+--------+\n",
      "|  en|  346302|\n",
      "|  es|   31869|\n",
      "| und|   14660|\n",
      "|  in|    2355|\n",
      "|  fr|     997|\n",
      "|  pt|     914|\n",
      "|  tl|     485|\n",
      "|  ht|     377|\n",
      "|  nl|     347|\n",
      "|  it|     285|\n",
      "+----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT lang,count(*)\n",
    "    FROM tweets\n",
    "    Group by lang\n",
    "    Order by count(*) DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here.\n",
    "The results are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 - Which 10 time zones are most common among users?  Verify your result with both the dataframe and SQL.\n",
    "\n",
    "*Note*: for this question, you may leave NULL values present in your results, as a way to help you understand what data is present and what is missing.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           time_zone| count|\n",
      "+--------------------+------+\n",
      "|                null|166386|\n",
      "|Pacific Time (US ...| 72214|\n",
      "|Central Time (US ...| 63665|\n",
      "|Eastern Time (US ...| 35889|\n",
      "|             Arizona| 10748|\n",
      "|Mountain Time (US...| 10057|\n",
      "|Atlantic Time (Ca...|  4805|\n",
      "|               Quito|  4397|\n",
      "|             Caracas|  4218|\n",
      "|         Mexico City|  3935|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets.groupby('user.time_zone').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|           time_zone|count(1)|\n",
      "+--------------------+--------+\n",
      "|Pacific Time (US ...|   72214|\n",
      "|Central Time (US ...|   63665|\n",
      "|Eastern Time (US ...|   35889|\n",
      "|             Arizona|   10748|\n",
      "|Mountain Time (US...|   10057|\n",
      "|Atlantic Time (Ca...|    4805|\n",
      "|               Quito|    4397|\n",
      "|             Caracas|    4218|\n",
      "|         Mexico City|    3935|\n",
      "|              Hawaii|    3489|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone,count(*)\n",
    "    FROM tweets\n",
    "    where user.time_zone is not null\n",
    "    Group by user.time_zone\n",
    "    Order by count(*) DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here.\n",
    "The results are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 - How many tweets mention the Dodgers?  How many mention the Astros?  How many mention both?\n",
    "\n",
    "You may use either the dataframe or SQL to answer.  Explain why you have chosen that approach.\n",
    "\n",
    "Hint:  you will want to look at the value of the `text` field.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "168218"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT text\n",
    "    FROM tweets\n",
    "    where text ilike '%Dodgers%'\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "246465"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT text\n",
    "    FROM tweets\n",
    "    where text ilike '%Astros%'\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49545"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT text\n",
    "    FROM tweets\n",
    "    where text ilike '%Astros%' \n",
    "    and text ilike '%Dodgers%'\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - More complex queries\n",
    "\n",
    "For this section, you may choose to use dataframe queries or SQL.  If you wish, you may verify results by using both, as in Part 2, but this is not required for this section.\n",
    "\n",
    "### Q3.1 - Team mentions by location\n",
    "\n",
    "In which users' locations are the Astros and the Dodgers being mentioned the most?  Consider each team separately, one at a time.  Discuss your findings. Do not count null time_zones or location.\n",
    "\n",
    "Hint:  you may use either the time zones or user-specified locations for this question.\n",
    "\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------+\n",
      "|           time_zone|   location|count(1)|\n",
      "+--------------------+-----------+--------+\n",
      "|Central Time (US ...|Houston, TX|    5742|\n",
      "|Pacific Time (US ...|Houston, TX|    1529|\n",
      "|Central Time (US ...| Texas, USA|    1288|\n",
      "|Central Time (US ...|      Texas|    1232|\n",
      "|Eastern Time (US ...|Houston, TX|    1223|\n",
      "+--------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone,user.location,count(*)\n",
    "    FROM tweets\n",
    "    where text ilike '%Astros%' \n",
    "    and user.location is not null\n",
    "    and user.time_zone is not null\n",
    "    Group by user.time_zone,user.location\n",
    "    Order by count(*) DESC\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------+\n",
      "|           time_zone|       location|count(1)|\n",
      "+--------------------+---------------+--------+\n",
      "|Pacific Time (US ...|Los Angeles, CA|    2972|\n",
      "|Pacific Time (US ...|    Los Angeles|    1280|\n",
      "|Pacific Time (US ...|California, USA|     873|\n",
      "|Central Time (US ...|    Houston, TX|     796|\n",
      "|Pacific Time (US ...|     California|     503|\n",
      "+--------------------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone,user.location,count(*)\n",
    "    FROM tweets\n",
    "    where text ilike '%Dodgers%' \n",
    "    and user.location is not null\n",
    "    and user.time_zone is not null\n",
    "    Group by user.time_zone,user.location\n",
    "    Order by count(*) DESC\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here.\n",
    "The Astros is mentioned the most in Houston, TX. The Dodgers is mentioned most in Los Angeles, CA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 - Which Twitter users are being replied to the most?\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "Hint: use the top-level `in_reply_to_screen_name` for this.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------+\n",
      "|in_reply_to_screen_name|count(1)|\n",
      "+-----------------------+--------+\n",
      "|                 astros|    4034|\n",
      "|                Dodgers|    3297|\n",
      "+-----------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT in_reply_to_screen_name,count(*)\n",
    "    FROM tweets\n",
    "    Where in_reply_to_screen_name is not null\n",
    "    group by in_reply_to_screen_name\n",
    "    order by count(*) DESC    \n",
    "\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here\n",
    "The astros is being replied to the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 - Which 10 verified users have the most followers?  Which 10 unverified users have the most followers?\n",
    "\n",
    "Provide both the screen names (screen_name) and follower counts (followers_count) for each.\n",
    "Verified users -- use verified == 't'\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------------+\n",
      "|       id|    screen_name|followers_count|\n",
      "+---------+---------------+---------------+\n",
      "| 99943864|Daminous_Purity|         998742|\n",
      "| 99943864|Daminous_Purity|         998731|\n",
      "| 99943864|Daminous_Purity|         998730|\n",
      "| 99943864|Daminous_Purity|         998722|\n",
      "| 99943864|Daminous_Purity|         998720|\n",
      "| 99943864|Daminous_Purity|         998684|\n",
      "| 29614331|        chochos|         833669|\n",
      "|202409095|     TexasHumor|         816301|\n",
      "|202409095|     TexasHumor|         816295|\n",
      "| 82971772|  el_carabobeno|         725952|\n",
      "+---------+---------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.id,user.screen_name,user.followers_count\n",
    "    FROM tweets\n",
    "    WHERE user.screen_name is not null\n",
    "    and user.verified != 't'\n",
    "    group by user.id,user.screen_name,user.followers_count\n",
    "    order by user.followers_count DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+--------+\n",
      "|       id|   screen_name|followers_count|verified|\n",
      "+---------+--------------+---------------+--------+\n",
      "|   428333|        cnnbrk|       53191119|    true|\n",
      "|   807095|       nytimes|       39959480|    true|\n",
      "|   759251|           CNN|       38209973|    true|\n",
      "|  1652541|       Reuters|       18937529|    true|\n",
      "|  1367531|       FoxNews|       16272836|    true|\n",
      "| 28785486|           ABC|       12551437|    true|\n",
      "|  2467791|washingtonpost|       11417638|    true|\n",
      "|236636515|   lopezdoriga|        7859821|    true|\n",
      "| 18479513|           MLB|        7841255|    true|\n",
      "| 18479513|           MLB|        7840827|    true|\n",
      "+---------+--------------+---------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.id,user.screen_name,user.followers_count,user.verified\n",
    "    FROM tweets\n",
    "    WHERE user.screen_name is not null\n",
    "    and user.verified == 't'\n",
    "    order by user.followers_count DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Verified users: Daminous_Purity,chochos,TexasHumor,el_carabobeno have the most followers. \n",
    "Unverified users: cnnbrk,nytimes,CNN,Reuters,FoxNews,ABC,washingtonpost,lopezdoriga,MLB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 - Analyze common words in tweet text\n",
    "\n",
    "Following the example in class, use `tweets.rdd` to find the most common interesting words in tweet text.  To keep it \"interesting\", remove at least 10 common stop words found in tweets, like \"a\", \"an\", \"the\", and \"RT\" (you might want to derive these stop words from initial results).  A simple split on text whitespace like we had in class is sufficient; you do not have to account for punctuation. \n",
    "\n",
    "After you find the most common words, use dataframe or SQL queries to find patterns among how those words are used.  For example, are they more frequently used by Dodgers or Astros fans, or by people in one part of the country over another?  Explore and see what you can find, and discuss your findings.\n",
    "\n",
    "You will notice that common words include words like \"thisteam\" and \"earnhistory\". I would like you to write two queries to investigate whether those two words are used by the Astros or Dodgers\n",
    "\n",
    "Hint: don't forget all the word count pipeline steps we used earlier in class.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = ['a','an','RT','to','the','in','am','is','are','I','and','of',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "word_count =tweets.rdd.flatMap(lambda r: r['text'].split(' ')) \\\n",
    "    .filter(lambda x : x not in stopword) \\\n",
    "    .map(lambda t: (t, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .takeOrdered(10, key=lambda pair: -pair[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Astros', 69114),\n",
       " ('', 62332),\n",
       " ('Dodgers', 52408),\n",
       " ('@astros:', 49821),\n",
       " ('#WorldSeries', 49706),\n",
       " ('for', 38574),\n",
       " ('@astros', 37272),\n",
       " ('#ThisTeam', 36593),\n",
       " ('#EarnHistory', 34614),\n",
       " ('this', 33225)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------+\n",
      "|                text|           time_zone|   location|count(1)|\n",
      "+--------------------+--------------------+-----------+--------+\n",
      "|RT @astros: The k...|Central Time (US ...|Houston, TX|     175|\n",
      "|RT @astros: Corre...|Central Time (US ...|Houston, TX|     151|\n",
      "|RT @astros: BREGM...|Central Time (US ...|Houston, TX|     150|\n",
      "|RT @astros: 🐐🐐?...|Central Time (US ...|Houston, TX|     127|\n",
      "|RT @astros: H-Tow...|Central Time (US ...|Houston, TX|      82|\n",
      "+--------------------+--------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check the time_zone and location of the Astros\n",
    "sqlc.sql(\"\"\"\n",
    "    SELECT text, user.time_zone,user.location ,count(*)\n",
    "    FROM tweets\n",
    "    where text ilike '%Astros%' \n",
    "    and user.time_zone is not null\n",
    "    and user.location is not null\n",
    "    group by text,user.time_zone,user.location\n",
    "    order by count(*) desc\n",
    "    \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|       location|count(1)|\n",
      "+---------------+--------+\n",
      "|    Houston, TX|    9584|\n",
      "|     Texas, USA|    1991|\n",
      "|          Texas|    1797|\n",
      "|Los Angeles, CA|    1639|\n",
      "|        Houston|    1636|\n",
      "| Houston, Texas|    1485|\n",
      "|     Austin, TX|    1047|\n",
      "|  United States|     882|\n",
      "|    Houston, Tx|     661|\n",
      "|San Antonio, TX|     619|\n",
      "+---------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.location ,count(*)\n",
    "    FROM tweets\n",
    "    where text ilike '%Astros%' \n",
    "    and user.time_zone is not null\n",
    "    and user.location is not null\n",
    "    group by user.location\n",
    "    order by count(*) desc\n",
    "    \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:==============================================>         (14 + 3) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|           location|count(1)|\n",
      "+-------------------+--------+\n",
      "|    Los Angeles, CA|    3452|\n",
      "|        Los Angeles|    1429|\n",
      "|        Houston, TX|    1131|\n",
      "|    California, USA|     949|\n",
      "|      United States|     561|\n",
      "|          Venezuela|     543|\n",
      "|             México|     539|\n",
      "|         California|     519|\n",
      "|         Texas, USA|     410|\n",
      "|Southern California|     328|\n",
      "+-------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.location ,count(*)\n",
    "    FROM tweets\n",
    "    where text like '%Dodgers%' \n",
    "    and user.time_zone is not null\n",
    "    and user.location is not null\n",
    "    group by user.location\n",
    "    order by count(*) desc\n",
    "    \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------------+\n",
      "|        id|               name|followers_count|\n",
      "+----------+-------------------+---------------+\n",
      "|  23043294|Los Angeles Dodgers|        1830535|\n",
      "|  23043294|Los Angeles Dodgers|        1829283|\n",
      "|  23043294|Los Angeles Dodgers|        1828991|\n",
      "|  23043294|Los Angeles Dodgers|        1828850|\n",
      "|  23043294|Los Angeles Dodgers|        1828646|\n",
      "|  23043294|Los Angeles Dodgers|        1828364|\n",
      "|  23043294|Los Angeles Dodgers|        1828222|\n",
      "|  23043294|Los Angeles Dodgers|        1828208|\n",
      "|  23043294|Los Angeles Dodgers|        1827973|\n",
      "|  23043294|Los Angeles Dodgers|        1827147|\n",
      "|  23043294|Los Angeles Dodgers|        1826697|\n",
      "|  23043294|Los Angeles Dodgers|        1826582|\n",
      "|  23043294|Los Angeles Dodgers|        1826491|\n",
      "|  23043294|Los Angeles Dodgers|        1826394|\n",
      "|  23043294|Los Angeles Dodgers|        1826010|\n",
      "|  23043294|Los Angeles Dodgers|        1825865|\n",
      "|2226855828| EL PINCHE DODGERS™|         144402|\n",
      "|2226855828| EL PINCHE DODGERS™|         144402|\n",
      "|2226855828| EL PINCHE DODGERS™|         144402|\n",
      "|  33602577|     Dodgers Nation|         138935|\n",
      "+----------+-------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find dodgers offical account id and name\n",
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.id,user.name, user.followers_count\n",
    "    FROM tweets\n",
    "    where user.name ilike '%Dodgers%'  \n",
    "    order by user.followers_count desc\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------------+\n",
      "|      id|          name|followers_count|\n",
      "+--------+--------------+---------------+\n",
      "|52803520|Houston Astros|        1086022|\n",
      "|52803520|Houston Astros|        1085833|\n",
      "|52803520|Houston Astros|        1085644|\n",
      "|52803520|Houston Astros|        1085349|\n",
      "|52803520|Houston Astros|        1085287|\n",
      "|52803520|Houston Astros|        1085125|\n",
      "|52803520|Houston Astros|        1084874|\n",
      "|52803520|Houston Astros|        1084132|\n",
      "|52803520|Houston Astros|        1083839|\n",
      "|52803520|Houston Astros|        1083651|\n",
      "|52803520|Houston Astros|        1083555|\n",
      "|52803520|Houston Astros|        1083397|\n",
      "|52803520|Houston Astros|        1083048|\n",
      "|52803520|Houston Astros|        1082771|\n",
      "|52803520|Houston Astros|        1082678|\n",
      "|52803520|Houston Astros|        1082221|\n",
      "|52803520|Houston Astros|        1082085|\n",
      "|52803520|Houston Astros|        1081998|\n",
      "|52803520|Houston Astros|        1081898|\n",
      "|52803520|Houston Astros|        1080761|\n",
      "+--------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find Astros offical accounr id and name \n",
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.id,user.name, user.followers_count\n",
    "    FROM tweets\n",
    "    where user.name ilike '%Astros%'  \n",
    "    order by user.followers_count desc\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find whether Astros use the word thisteam and earnhistory\n",
    "sqlc.sql(\"\"\"\n",
    "    SELECT text, user.id, user.name\n",
    "    FROM tweets\n",
    "    where user.id == '52803520' \n",
    "    and text ilike \"%ThisTeam%\"\n",
    "    and text ilike \"%EarnHistory%\"\n",
    "    \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|text|\n",
      "+----+\n",
      "+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT text\n",
    "    FROM tweets\n",
    "    where user.id like '52803520' \n",
    "    and text ilike \"%ThisTeam%\"\n",
    "    and text ilike \"%EarnHistory%\"\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find whether Astros use the word thisteam and earn history\n",
    "sqlc.sql(\"\"\"\n",
    "    SELECT text\n",
    "    FROM tweets\n",
    "    where user.id like '23043294' \n",
    "    and text ilike \"%ThisTeam%\"\n",
    "    and text ilike \"%EarnHistory%\"\n",
    "    \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
